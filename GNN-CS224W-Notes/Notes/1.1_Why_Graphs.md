# Introduction to Graph Neural Networks

**Video:** [Lecture 1 – Introduction to GNNs](https://www.youtube.com/watch?v=JAB_plj2rbA&list=PLoROMvodv4rPLKxIpqhjhPgdQy7imNkDn&index=1)  
**Official Course Slides:** [Stanford CS224W](https://web.stanford.edu/class/cs224w/slides/01-intro.pdf)

***

## Key Topics

- **Why Graphs Matter**  
  - Many real-world systems (social networks, molecules, knowledge graphs, etc.) can be modeled as graphs.
  - A graph perspective captures the relationships between entities (nodes) through interactions (edges).

- **Traditional ML vs. Graph ML**  
  - Traditional ML often relies on manual feature engineering, treating each sample independently.
  - In Graph ML, the model automatically extracts structural information through **representation learning**.

- **High-Level Overview of GNNs**  
  - GNNs learn node representations by iteratively aggregating and transforming features from neighboring nodes.
  - **Message Passing:** Nodes receive “messages” from adjacent nodes to update their embeddings.
  - **Mapping Nodes to Embeddings:** Each node is assigned a d-dimensional vector (in ℝ^d) so that similar nodes (in terms of structure and attributes) are embedded close together.

- **Unique Challenges in Graph Data**  
  - **No strict spatial locality:** Unlike images, graphs don’t have a regular grid structure.
  - **No universal reference point:** There’s no fixed origin to anchor node positions.
  - **No fixed ordering:** Nodes are not arranged in a specific order (e.g., left-to-right, top-to-bottom).

- **Core GNN Tasks**  
  - **Node-level:** Predict labels or properties for individual nodes (e.g., node classification).
  - **Link-level:** Predict the existence or strength of an edge (e.g., friend recommendations).
  - **Graph-level:** Classify or regress properties for entire graphs (e.g., molecule toxicity).

- **Applications**  
  - **Social Networks:** Friend recommendations, community detection.
  - **Recommendation Systems:** Product or content suggestions based on user–item interactions.
  - **Soccer Analytics:** GNNs can model complex interactions in sports (e.g., player positions and passing patterns); see [Tactics AI](https://deepmind.google/discover/blog/tacticai-ai-assistant-for-football-tactics/) for an example. (My work on this coming soon...)

***

## My Personal Takeaways

1. **Unified Perspective:**  
   GNNs bring together various graph-related tasks—node classification, link prediction, and more—under a single framework.

2. **Complexity of Graph Data:**  
   Graphs are inherently sparse and irregular, making the design and training of models more challenging compared to regular data formats like images or text.

3. **Representation Learning Advantage:**  
   With GNNs, there’s no need for extensive manual feature engineering; the model learns effective embeddings automatically through message passing.

4. **Excitement About Sports Analytics:**  
   The potential to analyze passing networks and player positions using GNNs could revolutionize team tactics and coaching strategies.

---

## Quotes or Interesting Points

> *“Graphs are a universal language to describe relationships.”*  
> (Paraphrased from the lecture)

This highlights the versatility and broad applicability of graphs across different domains.

***

## Next Steps

- **Lesson 1.2:**  
	In the next lesson, we’ll explore in depth the Graph ML applications examining node, edge, subgraph and graph-level tasks and their real-world impacts.

 - **Further Reading:**  
	Refer to the [Glossary](Glossary.html) for definitions and the [References]() for foundational papers.

***

**End of Lesson 01 Notes**
